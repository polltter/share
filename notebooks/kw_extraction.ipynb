{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "catholic-chuck",
   "metadata": {},
   "source": [
    "# C-More"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-paradise",
   "metadata": {},
   "source": [
    "### 1. Process text to extract keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "friendly-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-removal",
   "metadata": {},
   "source": [
    "#### 1.1. Load json data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valued-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_json = []\n",
    "\n",
    "with open('tweet_json_1day.txt') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        list_json.append(data)\n",
    "\n",
    "df = pd.DataFrame(list_json, columns = ['id', 'text', 'lang', 'created_at', 'public_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fiscal-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['retweets'] = df['public_metrics'].map(lambda x: x['retweet_count'])\n",
    "df['replies'] = df['public_metrics'].map(lambda x: x['reply_count'])\n",
    "df['likes'] = df['public_metrics'].map(lambda x: x['like_count'])\n",
    "df['quotes'] = df['public_metrics'].map(lambda x: x['quote_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bright-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('public_metrics', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "biological-defensive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1539397722595377152</td>\n",
       "      <td>@trashevrythng @hardevrythng @McDonalds and th...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T23:59:52.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1539397657571074049</td>\n",
       "      <td>@trashevrythng @hardevrythng @McDonalds respec...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T23:59:36.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1539397645625458688</td>\n",
       "      <td>@PeePosh2 @Scottschlittenh @sceley2011 @Joe_Ma...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T23:59:33.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1539397640680521730</td>\n",
       "      <td>-1000 https://t.co/dU6JWqNQsW</td>\n",
       "      <td>qst</td>\n",
       "      <td>2022-06-21T23:59:32.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1539397571013115904</td>\n",
       "      <td>@auauwra too bad im sending 8 mcdonalds large ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T23:59:16.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1539397722595377152  @trashevrythng @hardevrythng @McDonalds and th...   \n",
       "1  1539397657571074049  @trashevrythng @hardevrythng @McDonalds respec...   \n",
       "2  1539397645625458688  @PeePosh2 @Scottschlittenh @sceley2011 @Joe_Ma...   \n",
       "3  1539397640680521730                      -1000 https://t.co/dU6JWqNQsW   \n",
       "4  1539397571013115904  @auauwra too bad im sending 8 mcdonalds large ...   \n",
       "\n",
       "  lang                created_at  retweets  replies  likes  quotes  \n",
       "0   en  2022-06-21T23:59:52.000Z         0        0      3       0  \n",
       "1   en  2022-06-21T23:59:36.000Z         0        1      4       0  \n",
       "2   en  2022-06-21T23:59:33.000Z         0        2      4       0  \n",
       "3  qst  2022-06-21T23:59:32.000Z         0        0      1       0  \n",
       "4   en  2022-06-21T23:59:16.000Z         0        1      1       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dedicated-pickup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7153 entries, 0 to 7152\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          7153 non-null   object\n",
      " 1   text        7153 non-null   object\n",
      " 2   lang        7153 non-null   object\n",
      " 3   created_at  7153 non-null   object\n",
      " 4   retweets    7153 non-null   int64 \n",
      " 5   replies     7153 non-null   int64 \n",
      " 6   likes       7153 non-null   int64 \n",
      " 7   quotes      7153 non-null   int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 447.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-skiing",
   "metadata": {},
   "source": [
    "#### 1.2. Select only tweets in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extraordinary-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df[df['lang'] == 'en'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "special-marina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5377 entries, 0 to 7151\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          5377 non-null   object\n",
      " 1   text        5377 non-null   object\n",
      " 2   lang        5377 non-null   object\n",
      " 3   created_at  5377 non-null   object\n",
      " 4   retweets    5377 non-null   int64 \n",
      " 5   replies     5377 non-null   int64 \n",
      " 6   likes       5377 non-null   int64 \n",
      " 7   quotes      5377 non-null   int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 378.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-society",
   "metadata": {},
   "source": [
    "#### 1.3. Process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "worth-refund",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@bungoman @moothought @__justplaying @heavenbent11 @IgorBrigadir @huggingpuppy @flybottlemist @panchromaticity @temujin9 @Duderichy @jicapal @goblinodds @_brentbaum @scrmshw @OccultBoyscout @bogmeat @Knipps @OneEyedAlpaca @SoupOfToday @Acre108 @ObserverSuns @ZacharyHundley @_holyweather @anonynaut @magicianbrain @mimi10v3 @karnagraha @er1enney0ung @Lithros @parafactual @KrikkitMotel @__frye @eggprophet @pareinoia @TeddyRaccovelt @dancinghorse16 @storebrandguy @NLRG_ @irafeierabend @bloobsandnoods @RootOfUnity @VesselOfSpirit @MaskOfFace @ObjectOfObjects @CurlOfGradient @FingerOfHand @CauseOfProblem @ModelOfTheory @ReneeSolana @quotidiania Good morning to all you wonderful people. I just tried a new coffee from McDonalds and it is wonderful, just like you'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select longest tweet for testing purposes\n",
    "\n",
    "test_text = sorted(df_en['text'], key=lambda x: len(x), reverse=True)[0]\n",
    "\n",
    "test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-circumstances",
   "metadata": {},
   "source": [
    "We are going to use a tokenizer that that is particularly useful for social media texts: https://www.nltk.org/_modules/nltk/tokenize/casual.html#TweetTokenizer ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stable-discipline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'morning',\n",
       " 'to',\n",
       " 'all',\n",
       " 'you',\n",
       " 'wonderful',\n",
       " 'people',\n",
       " '.',\n",
       " 'I',\n",
       " 'just',\n",
       " 'tried',\n",
       " 'a',\n",
       " 'new',\n",
       " 'coffee',\n",
       " 'from',\n",
       " 'McDonalds',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'wonderful',\n",
       " ',',\n",
       " 'just',\n",
       " 'like',\n",
       " 'you']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_tokenizer = TweetTokenizer(reduce_len=True, strip_handles=True)\n",
    "# redule_len=True replaces repeated character sequences of length 3 or greater with sequences of length 3\n",
    "# examples: waaaaayyyy --> waaayyy\n",
    "# strip_handles=True removes Twitter handles (@xxxx...)\n",
    "\n",
    "tweet_tokenizer.tokenize(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-business",
   "metadata": {},
   "source": [
    "Our tokenizer keeps punctuation signs, which are not necessary for our task of keyword extraction. We are going to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "august-marriage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "seventh-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expressed-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct += \"’\" # add \"’\" to punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "professional-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct += \"…\" # add \"…\" to punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acknowledged-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct += \"...\" # add \"...\" to punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "banned-steam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~’…...'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "indian-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text and remove punctuation\n",
    "\n",
    "def tokens_nopunct(text):\n",
    "    \n",
    "    tokens = [token for token in TweetTokenizer(reduce_len=True, strip_handles=True).tokenize(text)]\n",
    "    return [token for token in tokens if token not in punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dominican-cooking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'morning',\n",
       " 'to',\n",
       " 'all',\n",
       " 'you',\n",
       " 'wonderful',\n",
       " 'people',\n",
       " 'I',\n",
       " 'just',\n",
       " 'tried',\n",
       " 'a',\n",
       " 'new',\n",
       " 'coffee',\n",
       " 'from',\n",
       " 'McDonalds',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'wonderful',\n",
       " 'just',\n",
       " 'like',\n",
       " 'you']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_nopunct(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-hygiene",
   "metadata": {},
   "source": [
    "As a final step, we can define a set of stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ancient-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "referenced-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-lexington",
   "metadata": {},
   "source": [
    "Scikit-learn also has its own set of stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "joined-williams",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sklearn_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-explosion",
   "metadata": {},
   "source": [
    "We can combine theses two sets (union) or use only the common stop words (intersection). We can also add or exclude any given words from our set of stop words."
   ]
  },
  {
   "cell_type": "raw",
   "id": "martial-squad",
   "metadata": {},
   "source": [
    "include_stopwords = {''}\n",
    "exclude_stopwords = {''}\n",
    "\n",
    "stopwords |= include_stopwords # union of sets\n",
    "stopwords &= sklearn_stop_words # intersection of sets\n",
    "stopwords -= exclude_stopwords # exclude words form our set of stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-console",
   "metadata": {},
   "source": [
    "We will use NLTK stop words for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "secure-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes stop words\n",
    "\n",
    "def remove_stop(tokens):\n",
    "    return [token for token in tokens if token not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "geographic-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [str.lower, tokens_nopunct, remove_stop] # this will be our default pipeline\n",
    "# lowercases words, tokenizes text, removes punctuation and removes stop words\n",
    "\n",
    "def process_text(text, pipeline):\n",
    "    tokens = text\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "coordinated-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en['tokens'] = df['text'].apply(process_text, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bronze-intent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quotes</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1539397722595377152</td>\n",
       "      <td>@trashevrythng @hardevrythng @McDonalds and th...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T23:59:52.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[breakfast]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1539397657571074049</td>\n",
       "      <td>@trashevrythng @hardevrythng @McDonalds respec...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T23:59:36.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[respect, chicken, nuggets, crispy, chicken, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1539397645625458688</td>\n",
       "      <td>@PeePosh2 @Scottschlittenh @sceley2011 @Joe_Ma...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T23:59:33.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[right, i'm, tapping, save, sanity, summing, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1539397571013115904</td>\n",
       "      <td>@auauwra too bad im sending 8 mcdonalds large ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T23:59:16.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[bad, im, sending, 8, mcdonalds, large, fries,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1539397434715082754</td>\n",
       "      <td>@_idkjia Last time I went to McDonalds.  lol  ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T23:58:43.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[last, time, went, mcdonalds, lol, https://t.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7146</th>\n",
       "      <td>1539035600451514375</td>\n",
       "      <td>if belos comes back we should just give him a ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T00:00:55.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[belos, comes, back, give, mcdonalds, sprite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7147</th>\n",
       "      <td>1539035573263863808</td>\n",
       "      <td>we were at mcdonalds and suddenly 4 school bus...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T00:00:49.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[mcdonalds, suddenly, 4, school, buses, filled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7149</th>\n",
       "      <td>1539035538300207104</td>\n",
       "      <td>IM SORRY I TOLD U TO DRINK MCDONALDS SPRITE ht...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T00:00:40.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[im, sorry, told, u, drink, mcdonalds, sprite,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>1539035499242864641</td>\n",
       "      <td>Tough times @McDonalds inflation is shrinking ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T00:00:31.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[tough, times, inflation, shrinking, large, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7151</th>\n",
       "      <td>1539035475352211456</td>\n",
       "      <td>@McDonalds It's literally raw so I am not sure...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-21T00:00:25.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[literally, raw, sure, shall]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5377 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "0     1539397722595377152  @trashevrythng @hardevrythng @McDonalds and th...   \n",
       "1     1539397657571074049  @trashevrythng @hardevrythng @McDonalds respec...   \n",
       "2     1539397645625458688  @PeePosh2 @Scottschlittenh @sceley2011 @Joe_Ma...   \n",
       "4     1539397571013115904  @auauwra too bad im sending 8 mcdonalds large ...   \n",
       "5     1539397434715082754  @_idkjia Last time I went to McDonalds.  lol  ...   \n",
       "...                   ...                                                ...   \n",
       "7146  1539035600451514375  if belos comes back we should just give him a ...   \n",
       "7147  1539035573263863808  we were at mcdonalds and suddenly 4 school bus...   \n",
       "7149  1539035538300207104  IM SORRY I TOLD U TO DRINK MCDONALDS SPRITE ht...   \n",
       "7150  1539035499242864641  Tough times @McDonalds inflation is shrinking ...   \n",
       "7151  1539035475352211456  @McDonalds It's literally raw so I am not sure...   \n",
       "\n",
       "     lang                created_at  retweets  replies  likes  quotes  \\\n",
       "0      en  2022-06-21T23:59:52.000Z         0        0      3       0   \n",
       "1      en  2022-06-21T23:59:36.000Z         0        1      4       0   \n",
       "2      en  2022-06-21T23:59:33.000Z         0        2      4       0   \n",
       "4      en  2022-06-21T23:59:16.000Z         0        1      1       0   \n",
       "5      en  2022-06-21T23:58:43.000Z         0        0      1       0   \n",
       "...   ...                       ...       ...      ...    ...     ...   \n",
       "7146   en  2022-06-21T00:00:55.000Z         1        0      3       0   \n",
       "7147   en  2022-06-21T00:00:49.000Z         0        0      0       0   \n",
       "7149   en  2022-06-21T00:00:40.000Z         0        0      1       1   \n",
       "7150   en  2022-06-21T00:00:31.000Z         0        1      2       0   \n",
       "7151   en  2022-06-21T00:00:25.000Z         0        0      0       0   \n",
       "\n",
       "                                                 tokens  \n",
       "0                                           [breakfast]  \n",
       "1     [respect, chicken, nuggets, crispy, chicken, s...  \n",
       "2     [right, i'm, tapping, save, sanity, summing, f...  \n",
       "4     [bad, im, sending, 8, mcdonalds, large, fries,...  \n",
       "5     [last, time, went, mcdonalds, lol, https://t.c...  \n",
       "...                                                 ...  \n",
       "7146      [belos, comes, back, give, mcdonalds, sprite]  \n",
       "7147  [mcdonalds, suddenly, 4, school, buses, filled...  \n",
       "7149  [im, sorry, told, u, drink, mcdonalds, sprite,...  \n",
       "7150  [tough, times, inflation, shrinking, large, fr...  \n",
       "7151                      [literally, raw, sure, shall]  \n",
       "\n",
       "[5377 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-leeds",
   "metadata": {},
   "source": [
    "We can now proceed to our second step and extract the most relevant keywords."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
